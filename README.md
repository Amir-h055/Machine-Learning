# [Machine Learning Project](https://github.com/axelsolano/432)
### Table of Contents
1. [Contributors](#Contributor)
2. [Guide](#Guide)
3. [Classification](#Classification)
4. [Regression](#Regression)
5. [Classifier interpretability](#Classifier-interpretability)
6. [Novelty](#Novelty)




</br>
</br>


## Contributor

@Amir-h055 AmirHossein </br>
@axelsolano Axel </br>
@annikatimermanis Annika </br>

</br>

##  Guide

This work is training of :
</br>8 classification datasets with 
    [Logistic regression (for classification)](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), 
    [Support vector classification](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html), 
    [Decision tree classification](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html), 
    [Random forest classification](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), 
    [k-nearest neighbours classification](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html), 
    [AdaBoost classification](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html), 
    [Gaussian naive Bayes classification](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html), 
    [Neural network classification](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html), 
</br>

8 classification datasets with 
    [Linear regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html), 
    [Support vector regression](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html), 
    [Decision tree regression](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html), 
    [Random forest regression](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html), 
    [kkk-nearest neighbours regression](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html), 
    [AdaBoost regression](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html), 
    [Gaussian process regression](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html), 
    [Neural network regression](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html), 
    
   </br>
 Compares the interpretability of a cnn versus a decision tree on same dataset. We wanted to observe which model performed better with classifying images out of 10 labels/targets. 
Outcome: the cnn produced a better score, and was more interpretable, this is depicted in the activation maximization where we show how feeding through a grey image to our trained cnn we can get similar patterns for a given class

    
   </br>
      </br>
Our project relies mainly on:

- sklearn
- pandas
- matplotlib
- PyTorch 
- Seaborn
- scipy
- numpy
   </br>
   </br>
    
## Classification
  -[Datatasets](project/Regression/Regression_Datasets)
  -[Code](project/Regression)
    </br>
  </br>   

-  [Diabetic Retinopathy](project/Classification/Diabetic_Retinopathy.ipynb), -->  [Link](https://archive.ics.uci.edu/ml/datasets/Diabetic+Retinopathy+Debrecen+Data+Set)  : <1h
-  [Default of credit card clients](project/Classification/Credit_Card_Clients.ipynb), -->  [Link](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)  : <1h
-  [Breast Cancer Wisconsin](project/Classification/Breast_Cancer_Wisconsin.ipynb), -->  [Link](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic))  : <1h
-  [Statlog (German credit data)](project/Classification/German_Credit_Data.ipynb), -->  [Link](https://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data))  : <1h
-  [Adult](project/Classification/Adult.ipynb), -->  [Link](https://archive.ics.uci.edu/ml/datasets/adult)  : +3h
-  [Yeast](project/Classification/Yeast.ipynb), -->  [Link](https://archive.ics.uci.edu/ml/datasets/Yeast)  : +4h
-  [Thoracic Surgery Data](project/Classification/Thoracic_Surgery_Data.ipynb), -->  [Link](https://archive.ics.uci.edu/ml/datasets/Thoracic+Surgery+Data)  : <1h
-  [Seismic-Bumps](project/Classification/Seismic_Bumps.ipynb), -->  [Link](https://archive.ics.uci.edu/ml/datasets/seismic-bumps)  : <1h



  
  
## Regression
  -[Datatasets](project/Classification/Classification_Datasets)
  -[Code](project/Classification)
   </br>
     </br> 
     
-  [White Wine Quality](project/Regression/White_Wine_Quality.ipynb), -->  [Link](http://archive.ics.uci.edu/ml/datasets/Wine+Quality)  : <1h
-  [Red Wine Quality](project/Regression/Red_Wine_Quality.ipynb), -->  [Link](http://archive.ics.uci.edu/ml/datasets/Wine+Quality)  : <1h
-  [Communities and Crime](project/Regression/Communities_and_Crime.ipynb), -->  [Link](http://archive.ics.uci.edu/ml/datasets/Communities+and+Crime)  : <1h
-  [QSAR aquatic toxicity](project/Regression/QSAR_Aquatic_Toxicity.ipynb), -->  [Link](http://archive.ics.uci.edu/ml/datasets/QSAR+aquatic+toxicity)  : <1h
-  [Facebook metrics](project/Regression/Facebook_Metrics.ipynb), -->  [Link](http://archive.ics.uci.edu/ml/datasets/Facebook+metrics)  : <1h
-  [Bike Sharing](project/Regression/Bike_Sharing.ipynb), -->  [Link](http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset)  : ~8h
-  [Student Performance](project/Regression/Student_Performance.ipynb), -->  [Link](http://archive.ics.uci.edu/ml/datasets/Student+Performance)  : <1h
-  [Concrete Compressive Strength](project/Regression/Concrete_Compressive_Strength.ipynb), -->  [Link](http://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength)  : <1h
-  [SGEMM GPU kernel performance](project/Regression/GPU_Kernel_Performance.ipynb), -->  [Link](http://archive.ics.uci.edu/ml/datasets/SGEMM+GPU+kernel+performance)  : +10h


 

## Classifier interpretability

   -[files](project/Part_3_Dataset)

## Novelty
